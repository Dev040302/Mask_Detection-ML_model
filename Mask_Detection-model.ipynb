{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={\"with_mask\":0,\"without_mask\":1}\n",
    "categories=[\"with_mask\",\"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"C:\\\\Users\\\\devan\\\\Desktop\\\\Data Set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "target=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories:\n",
    "    folder_path=os.path.join(data_path,category)\n",
    "    img_names=os.listdir(folder_path)\n",
    "    for img in img_names:\n",
    "        img_path=os.path.join(folder_path,img)\n",
    "        img=cv2.imread(img_path)\n",
    "        try:\n",
    "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            resized=cv2.resize(gray,(100,100))\n",
    "            data.append(resized)\n",
    "            target.append(label_dict[category])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1376, 100, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.array(data)\n",
    "data=data/255\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.reshape(data,(1376,100,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=np.array(target)\n",
    "new_target=np_utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(200,(3,3),activation=\"relu\",input_shape=data.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(50,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data,train_target,test_target=train_test_split(data,new_target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "39/39 [==============================] - 44s 1s/step - loss: 0.0299 - accuracy: 0.9871\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.0265 - accuracy: 0.9927\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.0290 - accuracy: 0.9887\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.0372 - accuracy: 0.9863\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.0179 - accuracy: 0.9927\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - 60s 2s/step - loss: 0.0103 - accuracy: 0.9968\n",
      "Epoch 7/20\n",
      "39/39 [==============================] - 93s 2s/step - loss: 0.0139 - accuracy: 0.9968\n",
      "Epoch 8/20\n",
      "39/39 [==============================] - 48s 1s/step - loss: 0.0329 - accuracy: 0.9871\n",
      "Epoch 9/20\n",
      "39/39 [==============================] - 37s 936ms/step - loss: 0.0176 - accuracy: 0.9960\n",
      "Epoch 10/20\n",
      "39/39 [==============================] - 38s 976ms/step - loss: 0.0150 - accuracy: 0.9952\n",
      "Epoch 11/20\n",
      "39/39 [==============================] - 47s 1s/step - loss: 0.0346 - accuracy: 0.9879\n",
      "Epoch 12/20\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.0228 - accuracy: 0.9919\n",
      "Epoch 13/20\n",
      "39/39 [==============================] - 42s 1s/step - loss: 0.0210 - accuracy: 0.9927\n",
      "Epoch 14/20\n",
      "39/39 [==============================] - 41s 1s/step - loss: 0.0127 - accuracy: 0.9976\n",
      "Epoch 15/20\n",
      "39/39 [==============================] - 38s 972ms/step - loss: 0.0199 - accuracy: 0.9943\n",
      "Epoch 16/20\n",
      "39/39 [==============================] - 39s 1s/step - loss: 0.0113 - accuracy: 0.9952\n",
      "Epoch 17/20\n",
      "39/39 [==============================] - 35s 908ms/step - loss: 0.0175 - accuracy: 0.9935\n",
      "Epoch 18/20\n",
      "39/39 [==============================] - 37s 945ms/step - loss: 0.0206 - accuracy: 0.9927\n",
      "Epoch 19/20\n",
      "39/39 [==============================] - 36s 932ms/step - loss: 0.0501 - accuracy: 0.9814\n",
      "Epoch 20/20\n",
      "39/39 [==============================] - 37s 959ms/step - loss: 0.0238 - accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2209fc28220>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,train_target,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameWidth= 640\n",
    "frameHeight = 480\n",
    "brightness = 180\n",
    "threshold = 0.75\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "def equalizer(img):\n",
    "    img=cv2.equalizeHist(img)\n",
    "    return img\n",
    "def preprocessing(img):\n",
    "    img=grayscale(img)\n",
    "    img=equalizer(img)\n",
    "    img=img/255\n",
    "    return img\n",
    "def getclass(classno):\n",
    "    if classno==0: return \"Mask is weared\"\n",
    "    elif classno==1: return \"Mask is not weared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "face=cv2.CascadeClassifier(\"C:\\AI\\AI\\haarcascades\\haarcascades\\haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-26d72342d229>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgO\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Processed Image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "while (1):\n",
    "    success,imgO=cap.read()\n",
    "    img=np.asarray(imgO)\n",
    "    img=cv2.resize(img,(100,100))\n",
    "    img=preprocessing(img)\n",
    "    cv2.imshow(\"Processed Image\",img)\n",
    "    img=img.reshape(1,100,100,1)\n",
    "    cv2.putText(imgO,\"Class: \",(20,35),font,0.75,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.putText(imgO,\"Probability: \",(20,75),font,0.75,(255,0,0),2,cv2.LINE_AA)\n",
    "    gray=grayscale(imgO)\n",
    "    faces=face.detectMultiScale(gray,1.1,10)\n",
    "    predictions=model.predict(img)\n",
    "    classIndex=model.predict_classes(img)\n",
    "    probabilityValue=np.amax(predictions)\n",
    "    if probabilityValue>0.75:\n",
    "        cv2.putText(imgO,str(classIndex) + \" \"+ str(getclass(classIndex)),(120,35),font,0.75,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.putText(imgO,str(round(probabilityValue*100,2)) + \"%\",(120,100),font,0.75,(255,0,),2,cv2.LINE_AA)\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "    cv2.imshow(\"Result\",imgO)\n",
    "    if(cv2.waitKey(1) & 0xFF==ord('q')):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
